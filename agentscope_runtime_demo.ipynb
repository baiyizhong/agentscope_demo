{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406e1e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from contextlib import asynccontextmanager\n",
    "from agentscope_runtime.engine import Runner\n",
    "from agentscope_runtime.engine.agents.llm_agent import LLMAgent\n",
    "from agentscope_runtime.engine.llms import QwenLLM\n",
    "from agentscope_runtime.engine.schemas.agent_schemas import (\n",
    "    MessageType,\n",
    "    RunStatus,\n",
    "    AgentRequest,\n",
    ")\n",
    "from agentscope_runtime.engine.services.context_manager import (\n",
    "    ContextManager,\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Dependencies imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T14:28:36.650765Z",
     "start_time": "2025-09-27T14:28:36.647189Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "from agentscope_runtime.engine import Runner\n",
    "from agentscope_runtime.engine.agents.llm_agent import LLMAgent\n",
    "from agentscope_runtime.engine.llms import QwenLLM\n",
    "from agentscope_runtime.engine.schemas.agent_schemas import AgentRequest\n",
    "from agentscope_runtime.engine.services.context_manager import ContextManager\n",
    "\n",
    "\n",
    "async def main():\n",
    "    # Set up the language model and agent\n",
    "    model = QwenLLM(\n",
    "        model_name=\"qwen-turbo\",\n",
    "        api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    )\n",
    "    llm_agent = LLMAgent(model=model, name=\"llm_agent\")\n",
    "\n",
    "    async with ContextManager() as context_manager:\n",
    "        runner = Runner(agent=llm_agent, context_manager=context_manager)\n",
    "\n",
    "        # Create a request and stream the response\n",
    "        request = AgentRequest(\n",
    "            input=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": \"What is the capital of France?\",\n",
    "                        },\n",
    "                    ],\n",
    "                },\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        async for message in runner.stream_query(request=request):\n",
    "            if hasattr(message, \"text\"):\n",
    "                print(f\"Streamed Answer: {message.text}\")\n",
    "\n",
    "\n",
    "# await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c86a1fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e699231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an LLM instance\n",
    "model = QwenLLM(\n",
    "    model_name=\"qwen-turbo\",\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\")\n",
    ")\n",
    "\n",
    "# Create the LLM Agent\n",
    "llm_agent = LLMAgent(\n",
    "    model=model,\n",
    "    name=\"llm_agent\",\n",
    "    description=\"A simple LLM agent for text generation\",\n",
    ")\n",
    "\n",
    "print(\"‚úÖ LLM Agent created successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf346ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agentscope.agent import ReActAgent\n",
    "from agentscope.model import OpenAIChatModel\n",
    "from agentscope_runtime.engine.agents.agentscope_agent import AgentScopeAgent\n",
    "\n",
    "agent = AgentScopeAgent(\n",
    "    name=\"Friday\",\n",
    "    model=OpenAIChatModel(\n",
    "        \"gpt-4\",\n",
    "        api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    ),\n",
    "    agent_config={\n",
    "        \"sys_prompt\": \"You're a helpful assistant named {name}.\",\n",
    "    },\n",
    "    agent_builder=ReActAgent,\n",
    ")\n",
    "\n",
    "print(\"‚úÖ AgentScope agent created successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267f62d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install \"agentscope-runtime[autogen]\"\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from agentscope_runtime.engine.agents.autogen_agent import AutogenAgent\n",
    "\n",
    "agent = AutogenAgent(\n",
    "    name=\"Friday\",\n",
    "    model = OpenAIChatCompletionClient(model=\"Qwen/Qwen3-235B-A22B\", model_info={\n",
    "                                                \"vision\": False,\n",
    "                                                \"function_calling\": True,\n",
    "                                                \"json_output\": True,\n",
    "                                                \"structured_output\": False,\n",
    "                                                \"family\": \"unknown\",},),\n",
    "    agent_config={\n",
    "        \"system_message\": \"You're a helpful assistant\",\n",
    "    },\n",
    "    agent_builder=AssistantAgent,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb547578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install \"agentscope-runtime[langgraph]\"\n",
    "from typing import TypedDict\n",
    "from langgraph import graph, types\n",
    "from agentscope_runtime.engine.agents.langgraph_agent import LangGraphAgent\n",
    "\n",
    "\n",
    "# define the state\n",
    "class State(TypedDict, total=False):\n",
    "    id: str\n",
    "\n",
    "\n",
    "# define the node functions\n",
    "async def set_id(state: State):\n",
    "    new_id = state.get(\"id\")\n",
    "    assert new_id is not None, \"must set ID\"\n",
    "    return types.Command(update=State(id=new_id), goto=\"REVERSE_ID\")\n",
    "\n",
    "\n",
    "async def reverse_id(state: State):\n",
    "    new_id = state.get(\"id\")\n",
    "    assert new_id is not None, \"ID must be set before reversing\"\n",
    "    return types.Command(update=State(id=new_id[::-1]))\n",
    "\n",
    "\n",
    "state_graph = graph.StateGraph(state_schema=State)\n",
    "state_graph.add_node(\"SET_ID\", set_id)\n",
    "state_graph.add_node(\"REVERSE_ID\", reverse_id)\n",
    "state_graph.set_entry_point(\"SET_ID\")\n",
    "compiled_graph = state_graph.compile(name=\"ID Reversal\")\n",
    "agent = LangGraphAgent(graph=compiled_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4f0c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@asynccontextmanager\n",
    "async def create_runner():\n",
    "    async with Runner(\n",
    "        agent=llm_agent,\n",
    "        context_manager=ContextManager(),\n",
    "    ) as runner:\n",
    "        print(\"‚úÖ Runner created successfully\")\n",
    "        yield runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2aa1a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def interact_with_agent(runner):\n",
    "    # Create a request\n",
    "    request = AgentRequest(\n",
    "        input=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": \"What is the capital of France?\",\n",
    "                    },\n",
    "                ],\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Stream the response\n",
    "    print(\"ü§ñ Agent is processing your request...\")\n",
    "    all_result = \"\"\n",
    "    async for message in runner.stream_query(request=request):\n",
    "        # Check if this is a completed message\n",
    "        if (\n",
    "            message.object == \"message\"\n",
    "            and MessageType.MESSAGE == message.type\n",
    "            and RunStatus.Completed == message.status\n",
    "        ):\n",
    "            all_result = message.content[0].text\n",
    "\n",
    "    print(f\"üìù Agent response: {all_result}\")\n",
    "    return all_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4e51fab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"time\": \"2025-09-28 22:00:10.847\", \"step\": \"agent_step_start\", \"model\": \"\", \"user_id\": \"\", \"code\": \"\", \"message\": \"\", \"task_id\": \"\", \"request_id\": \"\", \"context\": {\"request\": {\"input\": [{\"sequence_number\": null, \"object\": \"message\", \"status\": \"created\", \"error\": null, \"id\": \"msg_4ff92a15-4b8c-4da4-b9ca-c9f4dbc74ac9\", \"type\": \"message\", \"role\": \"user\", \"content\": [{\"sequence_number\": null, \"object\": \"content\", \"status\": null, \"error\": null, \"type\": \"text\", \"index\": null, \"delta\": false, \"msg_id\": null, \"text\": \"What is the capital of France?\"}], \"code\": null, \"message\": null, \"usage\": null}], \"stream\": true, \"model\": null, \"top_p\": null, \"temperature\": null, \"frequency_penalty\": null, \"presence_penalty\": null, \"max_tokens\": null, \"stop\": null, \"n\": 1, \"seed\": null, \"tools\": null, \"session_id\": null, \"response_id\": null}}, \"interval\": {\"type\": \"agent_step_start\", \"cost\": 0}, \"ds_service_id\": \"test_id\", \"ds_service_name\": \"test_name\"}\n",
      "{\"time\": \"2025-09-28 22:00:10.848\", \"step\": \"agent_step_first_resp\", \"model\": \"\", \"user_id\": \"\", \"code\": \"\", \"message\": \"\", \"task_id\": \"\", \"request_id\": \"\", \"context\": {\"sequence_number\": null, \"object\": \"response\", \"status\": \"created\", \"error\": null, \"id\": \"response_8e39c0f5-9e92-48c9-b229-eaf4791a8b10\", \"created_at\": 1759064525, \"completed_at\": null, \"output\": null, \"usage\": null, \"session_id\": null, \"request\": {\"input\": [{\"sequence_number\": null, \"object\": \"message\", \"status\": \"created\", \"error\": null, \"id\": \"msg_4ff92a15-4b8c-4da4-b9ca-c9f4dbc74ac9\", \"type\": \"message\", \"role\": \"user\", \"content\": [{\"sequence_number\": null, \"object\": \"content\", \"status\": null, \"error\": null, \"type\": \"text\", \"index\": null, \"delta\": false, \"msg_id\": null, \"text\": \"What is the capital of France?\"}], \"code\": null, \"message\": null, \"usage\": null}], \"stream\": true, \"model\": null, \"top_p\": null, \"temperature\": null, \"frequency_penalty\": null, \"presence_penalty\": null, \"max_tokens\": null, \"stop\": null, \"n\": 1, \"seed\": null, \"tools\": null, \"session_id\": null, \"response_id\": null}}, \"interval\": {\"type\": \"agent_step_first_resp\", \"cost\": \"0.001\"}, \"ds_service_id\": \"test_id\", \"ds_service_name\": \"test_name\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Runner created successfully\n",
      "ü§ñ Agent is processing your request...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"time\": \"2025-09-28 22:00:11.490\", \"step\": \"agent_step_end\", \"model\": \"\", \"user_id\": \"\", \"code\": \"\", \"message\": \"\", \"task_id\": \"\", \"request_id\": \"\", \"context\": {\"request\": {\"input\": [{\"sequence_number\": null, \"object\": \"message\", \"status\": \"created\", \"error\": null, \"id\": \"msg_4ff92a15-4b8c-4da4-b9ca-c9f4dbc74ac9\", \"type\": \"message\", \"role\": \"user\", \"content\": [{\"sequence_number\": null, \"object\": \"content\", \"status\": null, \"error\": null, \"type\": \"text\", \"index\": null, \"delta\": false, \"msg_id\": null, \"text\": \"What is the capital of France?\"}], \"code\": null, \"message\": null, \"usage\": null}], \"stream\": true, \"model\": null, \"top_p\": null, \"temperature\": null, \"frequency_penalty\": null, \"presence_penalty\": null, \"max_tokens\": null, \"stop\": null, \"n\": 1, \"seed\": null, \"tools\": null, \"session_id\": null, \"response_id\": null}}, \"interval\": {\"type\": \"agent_step_end\", \"cost\": \"0.643\"}, \"ds_service_id\": \"test_id\", \"ds_service_name\": \"test_name\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Agent response: The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "async def test_interaction():\n",
    "    async with create_runner() as runner:\n",
    "        await interact_with_agent(runner)\n",
    "\n",
    "await test_interaction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67196302",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agentscope_runtime.engine.deployers import LocalDeployManager\n",
    "\n",
    "async def deploy_agent(runner):\n",
    "    # Create deployment manager\n",
    "    deploy_manager = LocalDeployManager(\n",
    "        host=\"0.0.0.0\",\n",
    "        port=8090,\n",
    "    )\n",
    "\n",
    "    # Deploy the agent as a streaming service\n",
    "    deploy_result = await runner.deploy(\n",
    "        deploy_manager=deploy_manager,\n",
    "        endpoint_path=\"/process\",\n",
    "        stream=True,  # Enable streaming responses\n",
    "    )\n",
    "    print(f\"üöÄAgent deployed at: {deploy_result}\")\n",
    "    print(f\"üåê Service URL: {deploy_manager.service_url}\")\n",
    "    print(f\"üíö Health check: {deploy_manager.service_url}/health\")\n",
    "\n",
    "    return deploy_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184187e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_deployment():\n",
    "    async with create_runner() as runner:\n",
    "        deploy_manager = await deploy_agent(runner)\n",
    "\n",
    "    # Keep the service running (in production, you'd handle this differently)\n",
    "    print(\"üèÉ Service is running...\")\n",
    "\n",
    "    return deploy_manager\n",
    "\n",
    "# Deploy the agent\n",
    "deploy_manager = await run_deployment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a3e30609",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [5998]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Started server process [5998]\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Runner created successfully\n",
      "üöÄ Agent 1deployed: {'deploy_id': '161803c2-3e26-482c-a368-063d5a525e41', 'url': 'http://0.0.0.0:8092'}\n",
      "üöÄ Agent2 deployed: {'deploy_id': 'e41e544c-f4fc-41ab-ba37-401e67ff184c', 'url': 'http://0.0.0.0:8093'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Uvicorn running on http://0.0.0.0:8092 (Press CTRL+C to quit)\n",
      "INFO:     Uvicorn running on http://0.0.0.0:8093 (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "async def deploy_multiple_agents():\n",
    "    async with create_runner() as runner:\n",
    "        # Deploy multiple agents on different ports\n",
    "        deploy_manager1 = LocalDeployManager(host=\"0.0.0.0\", port=8092)\n",
    "        deploy_manager2 = LocalDeployManager(host=\"0.0.0.0\", port=8093)\n",
    "\n",
    "        # Deploy first agent\n",
    "        result1 = await runner.deploy(\n",
    "            deploy_manager=deploy_manager1,\n",
    "            endpoint_path=\"/agent1\",\n",
    "            stream=True,\n",
    "        )\n",
    "\n",
    "        # Deploy second agent (you could use different runner/agent)\n",
    "        result2 = await runner.deploy(\n",
    "            deploy_manager=deploy_manager2,\n",
    "            endpoint_path=\"/agent2\",\n",
    "            stream=True,\n",
    "        )\n",
    "\n",
    "        print(f\"üöÄ Agent 1deployed: {result1}\")\n",
    "        print(f\"üöÄ Agent2 deployed: {result2}\")\n",
    "\n",
    "        return deploy_manager1, deploy_manager2\n",
    "\n",
    "# Deploy multiple agents\n",
    "deploy_managers = await deploy_multiple_agents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "48deceab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing deployed agent...\n",
      "‚ùå Streaming test failed: HTTPConnectionPool(host='localhost', port=8090): Max retries exceeded with url: /process (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x116ed3920>: Failed to establish a new connection: [Errno 61] Connection refused'))\n",
      "‚ÑπÔ∏è JSON endpoint not available or failed: HTTPConnectionPool(host='localhost', port=8090): Max retries exceeded with url: /process (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x116f6f410>: Failed to establish a new connection: [Errno 61] Connection refused'))\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "def test_deployed_agent():\n",
    "    # Prepare the test payload\n",
    "    payload = {\n",
    "        \"input\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": \"What is the capital of France?\"},\n",
    "                ],\n",
    "            },\n",
    "        ],\n",
    "        \"session_id\": \"test_session_001\",\n",
    "        \"user_id\": \"test_user_001\",\n",
    "    }\n",
    "\n",
    "    print(\"üß™ Testing deployed agent...\")\n",
    "\n",
    "    # Test streaming responses\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            \"http://localhost:8090/process\",\n",
    "            json=payload,\n",
    "            stream=True,\n",
    "            timeout=30,\n",
    "        )\n",
    "\n",
    "        print(\"üì° Streaming Response:\")\n",
    "        for line in response.iter_lines():\n",
    "            if line:\n",
    "                print(f\"{line.decode('utf-8')}\")\n",
    "        print(\"‚úÖ Streaming test completed\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"‚ùå Streaming test failed: {e}\")\n",
    "\n",
    "    # Test JSON responses (if available)\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            \"http://localhost:8090/process\",\n",
    "            json=payload,\n",
    "            timeout=30,\n",
    "        )\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            print(f\"üìÑ JSON Response: {response.content}\")\n",
    "            print(\"‚úÖ JSON test completed\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è JSON endpoint returned status: {response.status_code}\")\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"‚ÑπÔ∏è JSON endpoint not available or failed: {e}\")\n",
    "\n",
    "\n",
    "# Run the test\n",
    "test_deployed_agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1581dbb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Service running: False\n",
      "Service URL: None\n"
     ]
    }
   ],
   "source": [
    "# Check service status\n",
    "print(f\"Service running: {deploy_manager.is_running}\")\n",
    "print(f\"Service URL: {deploy_manager.service_url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "26ee3d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üõë Service 0 stopped\n"
     ]
    }
   ],
   "source": [
    "async def stop_services(*_deploy_managers):\n",
    "    \"\"\"Stop deployed services\"\"\"\n",
    "    async def _stop():\n",
    "        for i, manager in enumerate(_deploy_managers):\n",
    "            if manager.is_running:\n",
    "                await manager.stop()\n",
    "            print(f\"üõë Service {i} stopped\")\n",
    "    await _stop()\n",
    "\n",
    "await stop_services(deploy_manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37b220f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentscope_demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
